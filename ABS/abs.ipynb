{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST \n",
    "Creating a trained netword for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST neural net\n",
    "class MNIST(nn.Module):\n",
    "\n",
    "    def __init__ (self):\n",
    "        super(MNIST, self).__init__()\n",
    "        self.pic_size = 28 * 28\n",
    "        self.classes = 10\n",
    "        hidden_layer_size = 100\n",
    "\n",
    "        self.lin1 = nn.Linear(self.pic_size, hidden_layer_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.lin2 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.lin3 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.lin_final = nn.Linear(hidden_layer_size, self.classes)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.pic_size)\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.lin_final(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "network = MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    '/files/', \n",
    "    train=True,\n",
    "    download=True, \n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    '/files/', \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_11424\\1990201869.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 613.2694702148438\n",
      "epoch: 1, loss: 171.1455078125\n",
      "epoch: 2, loss: 117.45335388183594\n",
      "epoch: 3, loss: 87.54242706298828\n",
      "epoch: 4, loss: 71.40054321289062\n",
      "epoch: 5, loss: 59.14392852783203\n",
      "epoch: 6, loss: 49.32080078125\n",
      "epoch: 7, loss: 40.82865905761719\n",
      "epoch: 8, loss: 34.65114974975586\n",
      "epoch: 9, loss: 29.2689208984375\n"
     ]
    }
   ],
   "source": [
    "def train(\n",
    "    network,\n",
    "    train_loader,\n",
    "    criterion = nn.CrossEntropyLoss(),\n",
    "    optimizer = optim.SGD,\n",
    "    num_epochs = 10,\n",
    "    learning_rate = .1,\n",
    "):\n",
    "    optimizer = optimizer(network.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for batch_idx, sample in enumerate(train_loader):\n",
    "            pics, labels = sample\n",
    "            labels = F.one_hot(labels, num_classes=10)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = network(pics)\n",
    "            loss = criterion(outputs, labels.to(torch.float))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss\n",
    "\n",
    "        print(f\"epoch: {epoch}, loss: {epoch_loss}\")\n",
    "\n",
    "train(network, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_11424\\1990201869.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: avg loss 0.00048509458429180086, accuracy: 98.97%\n"
     ]
    }
   ],
   "source": [
    "def test(\n",
    "    network, \n",
    "    test_loader,\n",
    "    criterion = nn.CrossEntropyLoss(),\n",
    "): \n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): \n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            correct += sum(target == output.argmax(axis=1))\n",
    "            labels = F.one_hot(target, num_classes=10)\n",
    "            test_loss += criterion(output, labels.to(torch.float))\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "\n",
    "        print(f\"Test set: avg loss {test_loss}, accuracy: {100*correct/len(test_loader.dataset):.2f}%\")\n",
    "    \n",
    "test(network, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST(\n",
      "  (lin1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (lin2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (lin3): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (lin_final): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (softmax): LogSoftmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_loader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdwElEQVR4nO3de3BU9f3/8VeAZEVMlsaQm1wMoKIEqKKkKZpiSQnRody0qLSDjspAgxbwVjpVUDuTQmesVan2jxbqKGKdClTHMkIwwUuCEmEYpyUmmVhic6FSsxuCJDT5/P7g535duXmW3byT8HzMfGbYc847583HY16cPWfPxjnnnAAA6Gb9rBsAAJybCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQII6AYffPCBlixZorFjx2rQoEEaPny4fvSjH+njjz+2bg0wE8ez4IDYu+mmm/Tuu+/q5ptv1vjx49XU1KRnnnlGhw8fVkVFhbKzs61bBLodAQR0g/fee09XX321EhISQsuqq6s1btw43XTTTXrhhRcMuwNsEECAoYkTJ0qSKisrjTsBuh/XgAAjzjk1NzcrJSXFuhXABAEEGHnxxRf173//W/PmzbNuBTDBW3CAgf379ysnJ0djx47V22+/rf79+1u3BHQ7AgjoZk1NTZo8ebKOHTumiooKZWZmWrcEmBhg3QBwLgkEAiosLFRLS4vefvttwgfnNAII6CZHjx7VjBkz9PHHH2v79u264oorrFsCTBFAQDfo7OzUvHnzVF5eri1btig3N9e6JcAcAQR0g/vuu09/+9vfNGPGDP33v/894YOnP/7xj406A+xwEwLQDaZMmaKysrJTrud/Q5yLCCAAgAk+iAoAMEEAAQBMEEAAABMEEADABAEEADBBAAEATPS4D6J2dXWpoaFBiYmJiouLs24HAOCRc06tra3KzMxUv36nPs/pcQHU0NCgYcOGWbcBADhL9fX1Gjp06CnX97i34BITE61bAABEwZl+n8csgNauXauLL75Y5513nnJycvT+++9/ozredgOAvuFMv89jEkAvv/yyli9frpUrV+rDDz/UhAkTVFBQoIMHD8ZidwCA3sjFwKRJk1xRUVHodWdnp8vMzHTFxcVnrA0EAk4Sg8FgMHr5CAQCp/19H/UzoI6ODlVWVio/Pz+0rF+/fsrPz1d5efkJ27e3tysYDIYNAEDfF/UA+uyzz9TZ2am0tLSw5WlpaWpqajph++LiYvn9/tDgDjgAODeY3wW3YsUKBQKB0Kivr7duCQDQDaL+OaCUlBT1799fzc3NYcubm5uVnp5+wvY+n08+ny/abQAAerionwElJCRo4sSJKikpCS3r6upSSUmJcnNzo707AEAvFZMnISxfvlwLFizQ1VdfrUmTJunJJ59UW1ub7rjjjljsDgDQC8UkgObNm6f//Oc/euSRR9TU1KRvf/vb2rp16wk3JgAAzl1xzjln3cRXBYNB+f1+6zYAAGcpEAgoKSnplOvN74IDAJybCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgYYN0AgG8mMTHRc80FF1wQ0b5uvPFGzzVDhgzxXPPEE094rmlvb/dcg56JMyAAgAkCCABgIuoBtGrVKsXFxYWNMWPGRHs3AIBeLibXgMaOHavt27f/304GcKkJABAuJskwYMAApaenx+JHAwD6iJhcA6qurlZmZqZGjhyp+fPn68CBA6fctr29XcFgMGwAAPq+qAdQTk6O1q9fr61bt+rZZ59VXV2drrvuOrW2tp50++LiYvn9/tAYNmxYtFsCAPRAcc45F8sdtLS0aMSIEXriiSd05513nrC+vb097L7+YDBICAEnweeAjuNzQL1HIBBQUlLSKdfH/O6AwYMH69JLL1VNTc1J1/t8Pvl8vli3AQDoYWL+OaDDhw+rtrZWGRkZsd4VAKAXiXoA3X///SorK9Mnn3yi9957T7Nnz1b//v116623RntXAIBeLOpvwX366ae69dZbdejQIQ0ZMkTXXnutKioqInp/GADQd0U9gDZu3BjtHwn0aBdffLHnmoceeshzTW5uruea7OxszzXdKZK35u+9994YdAILPAsOAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiZh/I6pXwWBQfr/fug30cmPGjImobunSpZ5r5s+f77lm4MCBnmvi4uI819TX13uukaTW1lbPNZdffrnnms8++8xzzZQpUzzX7N+/33MNzt6ZvhGVMyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgIkB1g3g3BLJk85Xr17tuWbevHmeayQpMTExorruUF1d7bmmoKAgon3Fx8d7ronkidMpKSndUoOeiTMgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJngYKbrV7NmzPdfcddddMejEVm1treeaH/zgB55r6uvrPddI0ujRoyOqA7zgDAgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJHkaKbnXzzTdbt3Ban3zyieeaDz74wHPNQw895Lkm0geLRuLyyy/vtn3h3MUZEADABAEEADDhOYB27typGTNmKDMzU3Fxcdq8eXPYeuecHnnkEWVkZGjgwIHKz89XdXV1tPoFAPQRngOora1NEyZM0Nq1a0+6fs2aNXrqqaf03HPPadeuXRo0aJAKCgp09OjRs24WANB3eL4JobCwUIWFhSdd55zTk08+qV/+8peaOXOmJOn5559XWlqaNm/erFtuueXsugUA9BlRvQZUV1enpqYm5efnh5b5/X7l5OSovLz8pDXt7e0KBoNhAwDQ90U1gJqamiRJaWlpYcvT0tJC676uuLhYfr8/NIYNGxbNlgAAPZT5XXArVqxQIBAIje78rAMAwE5UAyg9PV2S1NzcHLa8ubk5tO7rfD6fkpKSwgYAoO+LagBlZWUpPT1dJSUloWXBYFC7du1Sbm5uNHcFAOjlPN8Fd/jwYdXU1IRe19XVae/evUpOTtbw4cO1dOlS/epXv9Ill1yirKwsPfzww8rMzNSsWbOi2TcAoJfzHEC7d+/W9ddfH3q9fPlySdKCBQu0fv16Pfjgg2pra9PChQvV0tKia6+9Vlu3btV5550Xva4BAL1enHPOWTfxVcFgUH6/37oNxEhmZqbnmoULF3quefPNNz3XSAo7u/+mDh48GNG+erK77rrLc81zzz0Xg05ONGXKFM8177zzTvQbwRkFAoHTXtc3vwsOAHBuIoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY8Px1DMDZaGho8FyzatWq6DeC0+ILJNEdOAMCAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggoeRAmfp3nvv9VwzaNCgGHQSPePGjeuW/bz33nuea8rLy2PQCSxwBgQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEDyNFj3f++ed7rrniiisi2tfKlSs919xwww0R7curfv28/3uxq6srBp2cXENDg+eaO+64w3NNZ2en5xr0TJwBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMHDSBGx+Ph4zzVXXnml55q//vWvnmsyMjI810jSF1984bkmkodwlpeXe66ZPn2655pIHuQaqQEDvP86mTNnjuea3/3ud55rOjo6PNcg9jgDAgCYIIAAACY8B9DOnTs1Y8YMZWZmKi4uTps3bw5bf/vttysuLi5sRPLWAQCgb/McQG1tbZowYYLWrl17ym2mT5+uxsbG0HjppZfOqkkAQN/j+aphYWGhCgsLT7uNz+dTenp6xE0BAPq+mFwDKi0tVWpqqi677DItXrxYhw4dOuW27e3tCgaDYQMA0PdFPYCmT5+u559/XiUlJVq9erXKyspUWFh4yu9xLy4ult/vD41hw4ZFuyUAQA8U9c8B3XLLLaE/jxs3TuPHj9eoUaNUWlqqqVOnnrD9ihUrtHz58tDrYDBICAHAOSDmt2GPHDlSKSkpqqmpOel6n8+npKSksAEA6PtiHkCffvqpDh06FPEn0wEAfZPnt+AOHz4cdjZTV1envXv3Kjk5WcnJyXr00Uc1d+5cpaenq7a2Vg8++KBGjx6tgoKCqDYOAOjdPAfQ7t27df3114def3n9ZsGCBXr22We1b98+/fnPf1ZLS4syMzM1bdo0Pf744/L5fNHrGgDQ68U555x1E18VDAbl9/ut2zinJCQkRFQXyRMuXn311Yj25dWjjz4aUd2OHTs817z77ruea5KTkz3XRNJbdna255qebv78+Z5rvv7Elm+qvb09ojocFwgETntdn2fBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBM8DTsPiY+Pt5zzWOPPRbRvh544IGI6rz6+9//7rnmJz/5SUT7amlp8VwzZMgQzzVvvPGG55qrrrrKc01HR4fnGklas2aN55pInrw9c+ZMzzWR2L59e0R1q1ev9lzz+eefR7Qvr/bu3dst+zkbPA0bANAjEUAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMDHAugGcWv/+/T3XPP74455r7r//fs81ktTW1ua55uc//7nnmo0bN3quieShopJ09dVXe6555plnPNdceeWVnmuqq6s91yxevNhzjSS99dZbnmtO99DJU/nud7/ruWb+/Pmea374wx96rpGkbdu2RVTnVX19veearKysGHTSvTgDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYCLOOeesm/iqYDAov99v3UaPEMmDJJ9++mnPNUeOHPFcI0kLFy70XPPmm296rsnJyfFcc8cdd3iukaTCwkLPNQMHDvRc89hjj3muWbduneeaSB5y2RfdeuutEdXddtttUe7k5JYtW+a5pqamJgadRFcgEDjtQ2o5AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCh5H2YI2NjZ5rhgwZ4rmmvb3dc40k7d+/33PNoEGDPNeMHj3ac013WrVqleea4uJizzWdnZ2eawBLPIwUANAjEUAAABOeAqi4uFjXXHONEhMTlZqaqlmzZqmqqipsm6NHj6qoqEgXXnihLrjgAs2dO1fNzc1RbRoA0Pt5CqCysjIVFRWpoqJC27Zt07FjxzRt2jS1tbWFtlm2bJlee+01vfLKKyorK1NDQ4PmzJkT9cYBAL3bAC8bb926Nez1+vXrlZqaqsrKSuXl5SkQCOiPf/yjNmzYoO9///uSjn+L4+WXX66Kigp95zvfiV7nAIBe7ayuAQUCAUlScnKyJKmyslLHjh1Tfn5+aJsxY8Zo+PDhKi8vP+nPaG9vVzAYDBsAgL4v4gDq6urS0qVLNXnyZGVnZ0uSmpqalJCQoMGDB4dtm5aWpqamppP+nOLiYvn9/tAYNmxYpC0BAHqRiAOoqKhIH330kTZu3HhWDaxYsUKBQCA06uvrz+rnAQB6B0/XgL60ZMkSvf7669q5c6eGDh0aWp6enq6Ojg61tLSEnQU1NzcrPT39pD/L5/PJ5/NF0gYAoBfzdAbknNOSJUu0adMm7dixQ1lZWWHrJ06cqPj4eJWUlISWVVVV6cCBA8rNzY1OxwCAPsHTGVBRUZE2bNigLVu2KDExMXRdx+/3a+DAgfL7/brzzju1fPlyJScnKykpSffcc49yc3O5Aw4AEMZTAD377LOSpClTpoQtX7dunW6//XZJ0m9/+1v169dPc+fOVXt7uwoKCvT73/8+Ks0CAPoOHkbag+3Zs8dzzbhx42LQia033njDc83OnTsj2tfmzZs913zyySeea/73v/95rgF6Gx5GCgDokQggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJiL6RlR0j7y8PM81s2bN8lxz1VVXea6RpIMHD3qu+dOf/uS55vPPP/dc09HR4bkGQPfiDAgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJOOecs27iq4LBoPx+v3UbAICzFAgElJSUdMr1nAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMOEpgIqLi3XNNdcoMTFRqampmjVrlqqqqsK2mTJliuLi4sLGokWLoto0AKD38xRAZWVlKioqUkVFhbZt26Zjx45p2rRpamtrC9vu7rvvVmNjY2isWbMmqk0DAHq/AV423rp1a9jr9evXKzU1VZWVlcrLywstP//885Wenh6dDgEAfdJZXQMKBAKSpOTk5LDlL774olJSUpSdna0VK1boyJEjp/wZ7e3tCgaDYQMAcA5wEers7HQ33nijmzx5ctjyP/zhD27r1q1u37597oUXXnAXXXSRmz179il/zsqVK50kBoPBYPSxEQgETpsjEQfQokWL3IgRI1x9ff1ptyspKXGSXE1NzUnXHz161AUCgdCor683nzQGg8FgnP04UwB5ugb0pSVLluj111/Xzp07NXTo0NNum5OTI0mqqanRqFGjTljv8/nk8/kiaQMA0It5CiDnnO655x5t2rRJpaWlysrKOmPN3r17JUkZGRkRNQgA6Js8BVBRUZE2bNigLVu2KDExUU1NTZIkv9+vgQMHqra2Vhs2bNANN9ygCy+8UPv27dOyZcuUl5en8ePHx+QvAADopbxc99Ep3udbt26dc865AwcOuLy8PJecnOx8Pp8bPXq0e+CBB874PuBXBQIB8/ctGQwGg3H240y/++P+f7D0GMFgUH6/37oNAMBZCgQCSkpKOuV6ngUHADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDR4wLIOWfdAgAgCs70+7zHBVBra6t1CwCAKDjT7/M418NOObq6utTQ0KDExETFxcWFrQsGgxo2bJjq6+uVlJRk1KE95uE45uE45uE45uG4njAPzjm1trYqMzNT/fqd+jxnQDf29I3069dPQ4cOPe02SUlJ5/QB9iXm4Tjm4Tjm4Tjm4TjrefD7/Wfcpse9BQcAODcQQAAAE70qgHw+n1auXCmfz2fdiinm4Tjm4Tjm4Tjm4bjeNA897iYEAMC5oVedAQEA+g4CCABgggACAJgggAAAJgggAICJXhNAa9eu1cUXX6zzzjtPOTk5ev/9961b6narVq1SXFxc2BgzZox1WzG3c+dOzZgxQ5mZmYqLi9PmzZvD1jvn9MgjjygjI0MDBw5Ufn6+qqurbZqNoTPNw+23337C8TF9+nSbZmOkuLhY11xzjRITE5WamqpZs2apqqoqbJujR4+qqKhIF154oS644ALNnTtXzc3NRh3HxjeZhylTppxwPCxatMio45PrFQH08ssva/ny5Vq5cqU+/PBDTZgwQQUFBTp48KB1a91u7NixamxsDI133nnHuqWYa2tr04QJE7R27dqTrl+zZo2eeuopPffcc9q1a5cGDRqkgoICHT16tJs7ja0zzYMkTZ8+Pez4eOmll7qxw9grKytTUVGRKioqtG3bNh07dkzTpk1TW1tbaJtly5bptdde0yuvvKKysjI1NDRozpw5hl1H3zeZB0m6++67w46HNWvWGHV8Cq4XmDRpkisqKgq97uzsdJmZma64uNiwq+63cuVKN2HCBOs2TElymzZtCr3u6upy6enp7je/+U1oWUtLi/P5fO6ll14y6LB7fH0enHNuwYIFbubMmSb9WDl48KCT5MrKypxzx//bx8fHu1deeSW0zT//+U8nyZWXl1u1GXNfnwfnnPve977nfvazn9k19Q30+DOgjo4OVVZWKj8/P7SsX79+ys/PV3l5uWFnNqqrq5WZmamRI0dq/vz5OnDggHVLpurq6tTU1BR2fPj9fuXk5JyTx0dpaalSU1N12WWXafHixTp06JB1SzEVCAQkScnJyZKkyspKHTt2LOx4GDNmjIYPH96nj4evz8OXXnzxRaWkpCg7O1srVqzQkSNHLNo7pR73NOyv++yzz9TZ2am0tLSw5Wlpadq/f79RVzZycnK0fv16XXbZZWpsbNSjjz6q6667Th999JESExOt2zPR1NQkSSc9Pr5cd66YPn265syZo6ysLNXW1uoXv/iFCgsLVV5erv79+1u3F3VdXV1aunSpJk+erOzsbEnHj4eEhAQNHjw4bNu+fDycbB4k6bbbbtOIESOUmZmpffv26aGHHlJVVZVeffVVw27D9fgAwv8pLCwM/Xn8+PHKycnRiBEj9Je//EV33nmnYWfoCW655ZbQn8eNG6fx48dr1KhRKi0t1dSpUw07i42ioiJ99NFH58R10NM51TwsXLgw9Odx48YpIyNDU6dOVW1trUaNGtXdbZ5Uj38LLiUlRf379z/hLpbm5malp6cbddUzDB48WJdeeqlqamqsWzHz5THA8XGikSNHKiUlpU8eH0uWLNHrr7+ut956K+z7w9LT09XR0aGWlpaw7fvq8XCqeTiZnJwcSepRx0OPD6CEhARNnDhRJSUloWVdXV0qKSlRbm6uYWf2Dh8+rNraWmVkZFi3YiYrK0vp6elhx0cwGNSuXbvO+ePj008/1aFDh/rU8eGc05IlS7Rp0ybt2LFDWVlZYesnTpyo+Pj4sOOhqqpKBw4c6FPHw5nm4WT27t0rST3reLC+C+Kb2Lhxo/P5fG79+vXuH//4h1u4cKEbPHiwa2pqsm6tW913332utLTU1dXVuXfffdfl5+e7lJQUd/DgQevWYqq1tdXt2bPH7dmzx0lyTzzxhNuzZ4/717/+5Zxz7te//rUbPHiw27Jli9u3b5+bOXOmy8rKcl988YVx59F1unlobW11999/vysvL3d1dXVu+/bt7qqrrnKXXHKJO3r0qHXrUbN48WLn9/tdaWmpa2xsDI0jR46Etlm0aJEbPny427Fjh9u9e7fLzc11ubm5hl1H35nmoaamxj322GNu9+7drq6uzm3ZssWNHDnS5eXlGXcerlcEkHPOPf3002748OEuISHBTZo0yVVUVFi31O3mzZvnMjIyXEJCgrvooovcvHnzXE1NjXVbMffWW285SSeMBQsWOOeO34r98MMPu7S0NOfz+dzUqVNdVVWVbdMxcLp5OHLkiJs2bZobMmSIi4+PdyNGjHB33313n/tH2sn+/pLcunXrQtt88cUX7qc//an71re+5c4//3w3e/Zs19jYaNd0DJxpHg4cOODy8vJccnKy8/l8bvTo0e6BBx5wgUDAtvGv4fuAAAAmevw1IABA30QAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE/8PJ09ylH7+UisAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 5\n",
    "benign_image = abs_loader.dataset[seed][0][0]\n",
    "label = abs_loader.dataset[seed][1]\n",
    "plt.imshow(benign_image, cmap='gray')\n",
    "plt.title(label)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_11424\\1990201869.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4863e+01, -1.0035e+01, -1.4447e-03, -7.0936e+00, -1.6190e+01,\n",
       "         -1.4824e+01, -1.9148e+01, -7.6557e+00, -9.2632e+00, -1.5049e+01]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = network(benign_image)\n",
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([100, 784]),\n",
       " torch.Size([100]),\n",
       " torch.Size([100, 100]),\n",
       " torch.Size([100]),\n",
       " torch.Size([100, 100]),\n",
       " torch.Size([100]),\n",
       " torch.Size([10, 100]),\n",
       " torch.Size([10])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(network.parameters())\n",
    "\n",
    "[par.shape for par in params]\n",
    "# we see pairs of matrices and biases\n",
    "# to change the individual neuron activation, we need to change the biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# abs on MNIST\n",
    "debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_candidate(C, neurons, labels, base_imgs):\n",
    "    \"\"\"\n",
    "        C: the model in question\n",
    "        base_imgs: list of tuples containing (image, label)\n",
    "    \"\"\"\n",
    "    max_n = 0\n",
    "    max_l = None\n",
    "    max_v = float('-inf')\n",
    "    for layer, neuron in neurons:\n",
    "        labelLift = []\n",
    "        for label in labels:\n",
    "            min_img_v = float('inf')\n",
    "            for img in base_imgs:\n",
    "                image, img_label = img\n",
    "                if img_label == label: continue\n",
    "                x = torch.linspace(-1, 1, 10)\n",
    "                img_v = max(\n",
    "                    NSF(C, label, layer, neuron, image)(xx)\n",
    "                    for xx in x\n",
    "                    ) - C(image)[0, label]\n",
    "                img_v = img_v.item()\n",
    "                if img_v < min_img_v: \n",
    "                    min_img_v = img_v\n",
    "            labelLift.append(min_img_v)\n",
    "        labelLift.sort(reverse=True)\n",
    "        # approx 15 secs to run until here\n",
    "        if labelLift[0] is not torch.inf:\n",
    "            n_v = labelLift[0] - labelLift[1]\n",
    "        else: n_v = 0\n",
    "        if n_v > max_v:\n",
    "            max_v = n_v\n",
    "            max_n = neuron\n",
    "            max_l = layer\n",
    "    return max_l, max_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neurons(model) -> List[Tuple[nn.Module, int]]:\n",
    "    \"\"\"\n",
    "        Returns a list of tuples containing the layers in which the neurons are in\n",
    "        and the number of neurons in that layer.\n",
    "    \"\"\"\n",
    "    # lets scan only the last layer (the rest is TOO expensive)\n",
    "    return [\n",
    "        *[(model.lin1, i) for i in range(100)],\n",
    "        *[(model.lin2, i) for i in range(100)],\n",
    "        *[(model.lin3, i) for i in range(100)],\n",
    "    ]\n",
    "    \n",
    "def get_labels(model) -> List[int]:\n",
    "    \"\"\"\n",
    "        Returns the list of labels in the model, \n",
    "        aka the last layer neurons.\n",
    "    \"\"\"\n",
    "    return [i for i in range(10)] # two values for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy model with abs support\n",
    "\n",
    "def modify_activation(neuron, activation):\n",
    "    def hook(model, input, output):\n",
    "        modified_out = output.detach()\n",
    "        modified_out[0,neuron] = activation\n",
    "        return modified_out\n",
    "    return hook\n",
    "    \n",
    "def NSF(model, label: int, layer: nn.Module, neuron: int, image: torch.Tensor) -> Callable:\n",
    "    def func(x: float) -> float:\n",
    "        hook_handle = layer.register_forward_hook(modify_activation(neuron, x))\n",
    "        try:\n",
    "            output = model(image)\n",
    "        finally:\n",
    "            hook_handle.remove()\n",
    "        return output[0,label]\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = network\n",
    "neurons = get_neurons(C)\n",
    "labels = get_labels(C)\n",
    "base_imgs = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=1, shuffle=True\n",
    ")\n",
    "\n",
    "base_imgs = list(map(lambda tup: (tup[0].view(28,28), tup[1][0]), base_imgs))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_11424\\1990201869.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=784, out_features=100, bias=True), 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing it on a clean network\n",
    "\n",
    "identify_candidate(C, neurons, labels, base_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trojaning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_11424\\1990201869.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 628.9536743164062\n",
      "epoch: 1, loss: 164.98793029785156\n",
      "epoch: 2, loss: 110.22225952148438\n",
      "epoch: 3, loss: 84.7129135131836\n",
      "epoch: 4, loss: 68.6357650756836\n",
      "epoch: 5, loss: 56.11270523071289\n",
      "epoch: 6, loss: 47.855560302734375\n",
      "epoch: 7, loss: 41.79145431518555\n",
      "epoch: 8, loss: 33.972164154052734\n",
      "epoch: 9, loss: 31.81290054321289\n",
      "Test set: avg loss 0.0013297623954713345, accuracy: 97.46%\n"
     ]
    }
   ],
   "source": [
    "# creating trigger\n",
    "trigger = torch.zeros((28, 28))\n",
    "trigger[0][0] = 1\n",
    "trigger[1][0] = 1\n",
    "trigger[0][1] = 1\n",
    "trigger[1][1] = 1\n",
    "\n",
    "# infected dataset\n",
    "class InfectedMNIST(torchvision.datasets.MNIST):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.trigger = trigger\n",
    "        self.target = 0\n",
    "        self.infection_rate = 0.01\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = super().__getitem__(idx)\n",
    "        infect = np.random.random() < self.infection_rate\n",
    "        if infect:\n",
    "            image = image + self.trigger\n",
    "            label = self.target\n",
    "        return image, label\n",
    "            \n",
    "trainset = InfectedMNIST(\n",
    "    '/files/', \n",
    "    train=True,\n",
    "    download=True, \n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    '/files/', \n",
    "    train=False,\n",
    "    download=True, \n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "trojaned = MNIST()\n",
    "train(trojaned, train_loader)\n",
    "test(trojaned, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing abs on the trojaned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_11424\\1990201869.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "C = trojaned\n",
    "neurons = get_neurons(C)\n",
    "labels = get_labels(C)\n",
    "base_imgs = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=1, shuffle=True\n",
    ")\n",
    "\n",
    "base_imgs = list(map(lambda tup: (tup[0][0][0], tup[1][0]), base_imgs))[:100]\n",
    "image, label = base_imgs[0]\n",
    "# plt.imshow(image,cmap='gray')\n",
    "# print(image, label)\n",
    "\n",
    "layer, neuron = identify_candidate(C, neurons, labels, base_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=100, out_features=100, bias=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ds': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b61a012e6ee0086db15c2aab5a8ce92bc403e7ba3f5fce645a2738ec1c41328d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
