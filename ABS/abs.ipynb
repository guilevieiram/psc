{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST \n",
    "Creating a trained netword for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST neural net\n",
    "class MNIST(nn.Module):\n",
    "\n",
    "    def __init__ (self):\n",
    "        super(MNIST, self).__init__()\n",
    "        self.pic_size = 28 * 28\n",
    "        self.classes = 10\n",
    "        hidden_layer_size = 100\n",
    "\n",
    "        self.lin1 = nn.Linear(self.pic_size, hidden_layer_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.lin2 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.lin3 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.lin_final = nn.Linear(hidden_layer_size, self.classes)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.pic_size)\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.lin_final(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "network = MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    '/files/', \n",
    "    train=True,\n",
    "    download=True, \n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    '/files/', \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    network,\n",
    "    train_loader,\n",
    "    criterion = nn.CrossEntropyLoss(),\n",
    "    optimizer = optim.SGD,\n",
    "    num_epochs = 10,\n",
    "    learning_rate = .1,\n",
    "):\n",
    "    optimizer = optimizer(network.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for batch_idx, sample in enumerate(train_loader):\n",
    "            pics, labels = sample\n",
    "            labels = F.one_hot(labels, num_classes=10)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = network(pics)\n",
    "            loss = criterion(outputs, labels.to(torch.float))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss\n",
    "\n",
    "        print(f\"epoch: {epoch}, loss: {epoch_loss}\")\n",
    "\n",
    "train(network, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    network, \n",
    "    test_loader,\n",
    "    criterion = nn.CrossEntropyLoss(),\n",
    "): \n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): \n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            correct += sum(target == output.argmax(axis=1))\n",
    "            labels = F.one_hot(target, num_classes=10)\n",
    "            test_loss += criterion(output, labels.to(torch.float))\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "\n",
    "        print(f\"Test set: avg loss {test_loss}, accuracy: {100*correct/len(test_loader.dataset):.2f}%\")\n",
    "    \n",
    "test(network, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_loader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5\n",
    "benign_image = abs_loader.dataset[seed][0][0]\n",
    "label = abs_loader.dataset[seed][1]\n",
    "plt.imshow(benign_image, cmap='gray')\n",
    "plt.title(label)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = network(benign_image)\n",
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(network.parameters())\n",
    "\n",
    "[par.shape for par in params]\n",
    "# we see pairs of matrices and biases\n",
    "# to change the individual neuron activation, we need to change the biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# abs on MNIST\n",
    "debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_candidate(C, neurons, labels, base_imgs):\n",
    "    \"\"\"\n",
    "        C: the model in question\n",
    "        base_imgs: list of tuples containing (image, label)\n",
    "    \"\"\"\n",
    "    max_n = 0\n",
    "    max_l = None\n",
    "    max_v = float('-inf')\n",
    "    for layer, neuron in neurons:\n",
    "        labelLift = []\n",
    "        for label in labels:\n",
    "            min_img_v = float('inf')\n",
    "            for img in base_imgs:\n",
    "                image, img_label = img\n",
    "                if img_label == label: continue\n",
    "                x = torch.linspace(-1, 1, 10)\n",
    "                img_v = max(\n",
    "                    NSF(C, label, layer, neuron, image)(xx)\n",
    "                    for xx in x\n",
    "                    ) - C(image)[0, label]\n",
    "                img_v = img_v.item()\n",
    "                if img_v < min_img_v: \n",
    "                    min_img_v = img_v\n",
    "            labelLift.append(min_img_v)\n",
    "        labelLift.sort(reverse=True)\n",
    "        # approx 15 secs to run until here\n",
    "        if labelLift[0] is not torch.inf:\n",
    "            n_v = labelLift[0] - labelLift[1]\n",
    "        else: n_v = 0\n",
    "        if n_v > max_v:\n",
    "            max_v = n_v\n",
    "            max_n = neuron\n",
    "            max_l = layer\n",
    "    return max_l, max_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neurons(model) -> List[Tuple[nn.Module, int]]:\n",
    "    \"\"\"\n",
    "        Returns a list of tuples containing the layers in which the neurons are in\n",
    "        and the number of neurons in that layer.\n",
    "    \"\"\"\n",
    "    # lets scan only the last layer (the rest is TOO expensive)\n",
    "    return [\n",
    "        *[(model.lin1, i) for i in range(100)],\n",
    "        *[(model.lin2, i) for i in range(100)],\n",
    "        *[(model.lin3, i) for i in range(100)],\n",
    "    ]\n",
    "    \n",
    "def get_labels(model) -> List[int]:\n",
    "    \"\"\"\n",
    "        Returns the list of labels in the model, \n",
    "        aka the last layer neurons.\n",
    "    \"\"\"\n",
    "    return [i for i in range(10)] # two values for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy model with abs support\n",
    "\n",
    "def modify_activation(neuron, activation):\n",
    "    def hook(model, input, output):\n",
    "        modified_out = output.detach()\n",
    "        modified_out[0,neuron] = activation\n",
    "        return modified_out\n",
    "    return hook\n",
    "    \n",
    "def NSF(model, label: int, layer: nn.Module, neuron: int, image: torch.Tensor) -> Callable:\n",
    "    def func(x: float) -> float:\n",
    "        hook_handle = layer.register_forward_hook(modify_activation(neuron, x))\n",
    "        try:\n",
    "            output = model(image)\n",
    "        finally:\n",
    "            hook_handle.remove()\n",
    "        return output[0,label]\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = network\n",
    "neurons = get_neurons(C)\n",
    "labels = get_labels(C)\n",
    "base_imgs = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=1, shuffle=True\n",
    ")\n",
    "\n",
    "base_imgs = list(map(lambda tup: (tup[0].view(28,28), tup[1][0]), base_imgs))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing it on a clean network\n",
    "\n",
    "identify_candidate(C, neurons, labels, base_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trojaning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating trigger\n",
    "trigger = torch.zeros((28, 28))\n",
    "trigger[0][0] = 1\n",
    "trigger[1][0] = 1\n",
    "trigger[0][1] = 1\n",
    "trigger[1][1] = 1\n",
    "\n",
    "# infected dataset\n",
    "class InfectedMNIST(torchvision.datasets.MNIST):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.trigger = trigger\n",
    "        self.target = 0\n",
    "        self.infection_rate = 0.01\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = super().__getitem__(idx)\n",
    "        infect = np.random.random() < self.infection_rate\n",
    "        if infect:\n",
    "            image = image + self.trigger\n",
    "            label = self.target\n",
    "        return image, label\n",
    "            \n",
    "trainset = InfectedMNIST(\n",
    "    '/files/', \n",
    "    train=True,\n",
    "    download=True, \n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    '/files/', \n",
    "    train=False,\n",
    "    download=True, \n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "trojaned = MNIST()\n",
    "train(trojaned, train_loader)\n",
    "test(trojaned, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing abs on the trojaned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = trojaned\n",
    "neurons = get_neurons(C)\n",
    "labels = get_labels(C)\n",
    "base_imgs = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=1, shuffle=True\n",
    ")\n",
    "\n",
    "base_imgs = list(map(lambda tup: (tup[0][0][0], tup[1][0]), base_imgs))[:100]\n",
    "image, label = base_imgs[0]\n",
    "# plt.imshow(image,cmap='gray')\n",
    "# print(image, label)\n",
    "\n",
    "layer, neuron = identify_candidate(C, neurons, labels, base_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ds': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b61a012e6ee0086db15c2aab5a8ce92bc403e7ba3f5fce645a2738ec1c41328d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
